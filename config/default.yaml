#A sample configuration file:
#Which filetypes to ingest (pdf, markdown, html)
#Chunking strategy and its parameters (window size, overlap, etc.)
#Which metadata fields to extract


# ===============================
# üåê AutoEmbed: Default Config
# ===============================

# General Ingestion Settings
ingestion:
  input_folder: "../data/"
  accepted_filetypes: ["pdf", "markdown", "html"]
  include_metadata: true

# ===============================
# üß© Chunking Configuration
# ===============================
strats:
  - "sentence_aware"
  - "fixed_token"
  - "sliding_window"

sentence_max_tokens: 300

fixed_chunk_size: 10 

overlap: 5

# ===============================
# üî§ Tokenizer / Embedding Model
# ===============================
embedding:
  - provider: "openai"
    tokenizer_backend: "auto"
    max_tokens_per_chunk: 8191
        # Embedding model max (useful for validation)

# Used if provider == openai
openai:
  - model: "text-embedding-3-small"
    pricing_per_1k_tokens: 0.0001
    latency_ms: 300
                    # If false, calls hosted endpoint

# Used if provider == huggingface
huggingface:
  - model: "BAAI/bge-large-en"                 # If false, calls hosted endpoint
    latency_ms: 500
    pricing_per_1k_tokens: 0.0000    # Zero for local

# ===============================
# ‚öôÔ∏è Optimization Objectives
# ===============================
objectives:
  quality_target: "maximize"       # Options: maximize, min_recall@k, etc.
  max_latency_ms: 200              # Per-query latency constraint
  max_cost_per_10k_docs: 2.00      # Total embedding cost budget
  retrieval_top_k: 5               # Used in recall@k

# ===============================
# üìä Evaluation Settings
# ===============================
evaluation:
  generate_questions: true
  num_questions_per_doc: 3
  use_gpt4_for_answers: true       # Or manual, Claude, etc.
  eval_metrics: ["recall@k", "f1_overlap", "exact_match"]

# ===============================
# üß™ Experiment Metadata
# ===============================
experiment:
  name: "baseline_legal_docs_test"
  notes: "Testing chunk size vs. cost tradeoffs"
  save_outputs: true
  output_folder: "./logs/"