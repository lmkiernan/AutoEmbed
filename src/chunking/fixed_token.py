from src.tokenizer import get_token_counts


def fixed_token_chunk(text: str, doc_id: str, config: dict, model_provider_map: dict) -> list[dict]:
    max_tokens = config["fixed_chunk_size"]
    
    
    
    return []